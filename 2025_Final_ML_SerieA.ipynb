{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nickklos10/SerieA_Machine_Learning_Predictions_2025/blob/main/2025_Final_ML_SerieA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eenPg0lrdxJA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, Concatenate, Dropout, Lambda\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "import os\n",
        "from functools import partial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZCQcKROd7Ga",
        "outputId": "3b4c3f7f-3f8d-471d-e7bf-4f1dac173219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TensorFlow version: 2.18.0\n",
            "Using SHAP version: 0.47.1\n"
          ]
        }
      ],
      "source": [
        "print(f\"Using TensorFlow version: {tf.__version__}\")\n",
        "print(f\"Using SHAP version: {shap.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SPp8cTueBeh"
      },
      "source": [
        "# --- Configuration Constants ---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWs4I9Ind83M"
      },
      "outputs": [],
      "source": [
        "# Files and Paths\n",
        "DATA_FILEPATH = '/content/final_merged_data_with_transfers.csv'\n",
        "PREDICTIONS_OUTPUT_FILE = 'final_2025_predictions_refactored.csv'\n",
        "SHAP_SUMMARY_PLOT_FILE = \"shap_summary_plot.png\"\n",
        "SHAP_DEPENDENCE_PLOT_PREFIX = \"shap_dependence_\"\n",
        "\n",
        "# Data Columns\n",
        "TARGET_POINTS_COL = 'Pti'\n",
        "TARGET_RESULTS_COLS = ['Vit', 'Par', 'Sco']\n",
        "GIO_COL = 'Gio' # Games Played\n",
        "CATEGORICAL_COLS = ['Team', 'Coach']\n",
        "LOG_TRANSFORM_COLS = [\n",
        "    'Average Market Value', 'Total Market Value', 'Market Value IN Players',\n",
        "    'Market Value OUT Players', 'Fees Players IN', 'Fees Players OUT', 'Net_Spent'\n",
        "]\n",
        "BASE_INPUT_FEATURES = [\n",
        "    'Squad Size', 'Average Age', 'Foreigners',\n",
        "    'Average Market Value', 'Total Market Value', 'Players In', 'Players Out',\n",
        "    'Average Age IN players', 'Average Age OUT players',\n",
        "    'Market Value IN Players', 'Market Value OUT Players',\n",
        "    'Fees Players IN', 'Fees Players OUT', 'Net_Spent'\n",
        "]\n",
        "\n",
        "# Modeling Parameters\n",
        "UNKNOWN_TOKEN_ID = 0 # Reserve index 0 for unknown categories\n",
        "RANDOM_SEED = 42\n",
        "LAST_COMPLETED_YEAR = 2023\n",
        "PREDICTION_YEAR_OFFSET = 2 # Predict for last_completed_year + 2 (e.g., 2025 if last is 2023)\n",
        "FULL_SEASON_GAMES = 38 # Assumed games in the prediction year season\n",
        "IMPUTATION_STRATEGY = 'median'\n",
        "\n",
        "# Neural Network Hyperparameters\n",
        "TEAM_EMBEDDING_DIM = 10 # Increased from 5 for potentially more capacity\n",
        "COACH_EMBEDDING_DIM = 8  # Increased from 5\n",
        "DROPOUT_RATE = 0.3\n",
        "LEARNING_RATE = 0.001 # Standard Adam default, can be tuned\n",
        "LOSS_WEIGHTS = {'points_output': 1.0, 'results_output': 1.0} # Can be tuned\n",
        "\n",
        "# Training Parameters\n",
        "EPOCHS = 150 # Increased epochs, relying on EarlyStopping\n",
        "BATCH_SIZE = 32\n",
        "EARLY_STOPPING_PATIENCE = 15 # Increased patience\n",
        "\n",
        "# Post-Processing Parameters\n",
        "ADJUST_OUTCOMES_SEARCH_WINDOW = 5 # Window size (+/-) for searching W/D in adjust_outcomes\n",
        "\n",
        "# SHAP Parameters\n",
        "SHAP_BACKGROUND_SAMPLES = 20\n",
        "SHAP_EXPLAIN_SAMPLES = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t97Yb7gzeMC1"
      },
      "source": [
        "# --- Utility Functions ---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBnvSSnZeJrg"
      },
      "outputs": [],
      "source": [
        "def set_seeds(seed_value):\n",
        "    \"\"\"Sets random seeds for reproducibility.\"\"\"\n",
        "    np.random.seed(seed_value)\n",
        "    tf.random.set_seed(seed_value)\n",
        "    # Set PYTHONHASHSEED environment variable if needed (usually before script start)\n",
        "    # os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "    print(f\"Random seeds set to {seed_value}\")\n",
        "\n",
        "def create_output_directory(dir_name=\"output_plots\"):\n",
        "    \"\"\"Creates a directory if it doesn't exist.\"\"\"\n",
        "    if not os.path.exists(dir_name):\n",
        "        os.makedirs(dir_name)\n",
        "        print(f\"Created directory: {dir_name}\")\n",
        "    return dir_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft49xsd_ePvw"
      },
      "source": [
        "# --- Data Loading and Preprocessing ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FdO12teeQFX"
      },
      "outputs": [],
      "source": [
        "def load_data(filepath):\n",
        "    \"\"\"Loads data from CSV and cleans column names.\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(filepath)\n",
        "        df.columns = df.columns.str.strip()\n",
        "        print(f\"Data loaded successfully from {filepath}. Shape: {df.shape}\")\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Data file not found at {filepath}\")\n",
        "        return None\n",
        "\n",
        "def preprocess_data(df, target_points_col, target_results_cols, input_features_cols,\n",
        "                      log_features_cols, gio_col, categorical_cols,\n",
        "                      imputation_strategy='median'): # Removed unknown_token_id arg\n",
        "    \"\"\"Applies preprocessing: log transforms, imputation, categorical encoding (starting from 1).\"\"\"\n",
        "    df_processed = df.copy()\n",
        "    final_numeric_features = list(input_features_cols)\n",
        "\n",
        "    # 1. Log Transforms\n",
        "    print(\"Applying Log Transforms...\")\n",
        "    # ... (keep existing log transform code) ...\n",
        "    for feature in log_features_cols:\n",
        "        if feature in df_processed.columns:\n",
        "            df_processed[feature] = df_processed[feature].clip(lower=0)\n",
        "            log_feature_name = f'{feature}_log'\n",
        "            df_processed[log_feature_name] = np.log1p(df_processed[feature])\n",
        "            if log_feature_name not in final_numeric_features:\n",
        "                final_numeric_features.append(log_feature_name)\n",
        "        else:\n",
        "            print(f\"Warning: Log feature '{feature}' not found in DataFrame.\")\n",
        "\n",
        "\n",
        "    # 2. Imputation (Do this BEFORE encoding if needed on categoricals, but usually on numeric)\n",
        "    # Apply imputation only to numeric features identified so far\n",
        "    print(f\"Applying {imputation_strategy} imputation to numeric features...\")\n",
        "    imputer = SimpleImputer(strategy=imputation_strategy)\n",
        "    # Fit and transform numeric columns - hold imputed data temporarily\n",
        "    numeric_imputed = imputer.fit_transform(df_processed[final_numeric_features])\n",
        "    # Assign back to the dataframe\n",
        "    df_processed[final_numeric_features] = numeric_imputed\n",
        "    imputers = {'numeric': imputer} # Store imputer\n",
        "\n",
        "\n",
        "    # 3. Categorical Encoding (Start labels from 1, handle unknowns during predict)\n",
        "    encoders = {}\n",
        "    print(\"Applying Label Encoding (starting labels from 1)...\")\n",
        "    categorical_label_cols = []\n",
        "    for col in categorical_cols:\n",
        "        le = LabelEncoder()\n",
        "        # Fit on known values\n",
        "        unique_values = df_processed[col].astype(str).unique()\n",
        "        le.fit(unique_values)\n",
        "        encoders[col] = le\n",
        "\n",
        "        label_col = f'{col}_Label'\n",
        "        categorical_label_cols.append(label_col)\n",
        "        # Transform known values, assign a placeholder (e.g., 0) for unknowns initially\n",
        "        # We add 1 to shift labels away from 0. Unknowns will be handled during prediction transform.\n",
        "        # Store the mapping size (number of classes + 1 for the 0 placeholder)\n",
        "        raw_labels = df_processed[col].astype(str).apply(lambda x: x if x in le.classes_ else 'unknown_placeholder')\n",
        "        # Temporarily add placeholder to fit correctly if needed, then remove before setting vocab size\n",
        "        temp_classes = np.append(le.classes_, ['unknown_placeholder'])\n",
        "        le.classes_ = temp_classes\n",
        "        transformed_labels_with_placeholder = le.transform(raw_labels)\n",
        "        le.classes_ = le.classes_[:-1] # Remove placeholder\n",
        "\n",
        "        # Now map placeholder to 0, and shift others up by 1\n",
        "        df_processed[label_col] = np.where(transformed_labels_with_placeholder == len(le.classes_), 0, transformed_labels_with_placeholder + 1)\n",
        "\n",
        "        print(f\"Encoded '{col}' into '{label_col}'. Vocab size (incl. 0 for unknown): {len(le.classes_) + 1}\")\n",
        "\n",
        "\n",
        "    all_features_processed = final_numeric_features + categorical_label_cols + [gio_col]\n",
        "\n",
        "    # Return categorical_label_cols as well\n",
        "    return df_processed, encoders, final_numeric_features, imputers, categorical_label_cols\n",
        "\n",
        "# Make sure this is the definition being used:\n",
        "def prepare_scaled_data_for_training(df_processed, train_indices, val_indices, numeric_features,\n",
        "                                     gio_col, target_points_col, target_results_cols,\n",
        "                                     categorical_label_cols): # Removed imputers from definition arguments\n",
        "    \"\"\"Splits data, applies scaling, prepares model inputs/outputs. Assumes imputation already done.\"\"\"\n",
        "\n",
        "    X_train_df = df_processed.loc[train_indices]\n",
        "    X_val_df = df_processed.loc[val_indices]\n",
        "\n",
        "    # 1. Scaling Numeric Features (fit on train, transform train/val) - Data is already imputed\n",
        "    print(\"Scaling numeric input features...\")\n",
        "    scaler_input = StandardScaler()\n",
        "    X_train_numeric_scaled = scaler_input.fit_transform(X_train_df[numeric_features])\n",
        "    X_val_numeric_scaled = scaler_input.transform(X_val_df[numeric_features])\n",
        "\n",
        "    # 2. Scaling Target Points (fit on train, transform train/val)\n",
        "    print(\"Scaling points target variable...\")\n",
        "    scaler_points = StandardScaler()\n",
        "    y_train_points = scaler_points.fit_transform(X_train_df[[target_points_col]])\n",
        "    y_val_points = scaler_points.transform(X_val_df[[target_points_col]])\n",
        "\n",
        "    # 3. Prepare Other Inputs/Outputs (no scaling needed)\n",
        "    X_train_gio = X_train_df[gio_col].values.reshape(-1, 1).astype(np.float32)\n",
        "    X_val_gio = X_val_df[gio_col].values.reshape(-1, 1).astype(np.float32)\n",
        "\n",
        "    y_train_results = X_train_df[target_results_cols].values.astype(np.float32)\n",
        "    y_val_results = X_val_df[target_results_cols].values.astype(np.float32)\n",
        "\n",
        "    X_train_cats = {col: X_train_df[col].values for col in categorical_label_cols}\n",
        "    X_val_cats = {col: X_val_df[col].values for col in categorical_label_cols}\n",
        "\n",
        "    # Prepare inputs as lists/dictionaries for model.fit\n",
        "    X_train_list = [X_train_numeric_scaled, X_train_cats['Team_Label'], X_train_cats['Coach_Label'], X_train_gio]\n",
        "    X_val_list = [X_val_numeric_scaled, X_val_cats['Team_Label'], X_val_cats['Coach_Label'], X_val_gio]\n",
        "    y_train_dict = {'points_output': y_train_points, 'results_output': y_train_results}\n",
        "    y_val_dict_scaled = {'points_output': y_val_points, 'results_output': y_val_results}\n",
        "\n",
        "    scalers = {'input': scaler_input, 'points': scaler_points}\n",
        "\n",
        "    print(\"Data scaling and preparation complete.\")\n",
        "    return X_train_list, y_train_dict, X_val_list, y_val_dict_scaled, scalers # Return scalers only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZvsNEVwecBr"
      },
      "source": [
        "# --- Model Building ---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFjQpEQyecYF"
      },
      "outputs": [],
      "source": [
        "def build_multitask_model(num_numeric_features, num_teams, num_coaches,\n",
        "                          team_embedding_dim, coach_embedding_dim,\n",
        "                          dropout_rate, learning_rate, loss_weights): # Removed unknown_token_id arg\n",
        "    \"\"\"Builds the Keras multi-task model without mask_zero.\"\"\"\n",
        "\n",
        "    numeric_input = Input(shape=(num_numeric_features,), name='numeric_input')\n",
        "    team_input = Input(shape=(1,), name='team_input', dtype='int32')\n",
        "    coach_input = Input(shape=(1,), name='coach_input', dtype='int32')\n",
        "    gio_input = Input(shape=(1,), name='gio_input', dtype='float32')\n",
        "\n",
        "    # input_dim = vocab_size + 1 (index 0 for unknown, 1 to N for known categories)\n",
        "    team_vocab_size = num_teams + 1\n",
        "    coach_vocab_size = num_coaches + 1\n",
        "\n",
        "    team_embedding_layer = Embedding(input_dim=team_vocab_size, output_dim=team_embedding_dim,\n",
        "                                     name='team_embedding', mask_zero=False) # Set mask_zero=False\n",
        "    team_embedding = team_embedding_layer(team_input)\n",
        "    team_embedding = Flatten()(team_embedding)\n",
        "\n",
        "    coach_embedding_layer = Embedding(input_dim=coach_vocab_size, output_dim=coach_embedding_dim,\n",
        "                                      name='coach_embedding', mask_zero=False) # Set mask_zero=False\n",
        "    coach_embedding = coach_embedding_layer(coach_input)\n",
        "    coach_embedding = Flatten()(coach_embedding)\n",
        "\n",
        "    # ... rest of the model architecture ...\n",
        "    shared = Concatenate()([numeric_input, team_embedding, coach_embedding])\n",
        "    x = Dense(128, activation='relu')(shared)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Branch 1: Points prediction\n",
        "    points_output = Dense(1, activation='linear', name='points_output')(x)\n",
        "\n",
        "    # Branch 2: Match outcomes prediction (Vit, Par, Sco)\n",
        "    results_logits = Dense(3, activation='linear')(x)\n",
        "    results_probs = tf.keras.layers.Activation('softmax', name='results_probs')(results_logits)\n",
        "    results_output = Lambda(lambda inputs: inputs[0] * inputs[1], name='results_output')([results_probs, gio_input])\n",
        "\n",
        "    model = Model(inputs=[numeric_input, team_input, coach_input, gio_input],\n",
        "                  outputs=[points_output, results_output])\n",
        "\n",
        "    losses = { 'points_output': 'mse', 'results_output': 'mse' }\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss=losses, loss_weights=loss_weights)\n",
        "    print(\"Model compiled successfully (mask_zero=False).\")\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtIaoA8CekvA"
      },
      "source": [
        "# --- Model Training ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUeX0K-8elIh"
      },
      "outputs": [],
      "source": [
        "def train_model(model, X_train_list, y_train_dict, X_val_list, y_val_dict,\n",
        "                epochs, batch_size, patience):\n",
        "    \"\"\"Trains the model with early stopping.\"\"\"\n",
        "    print(\"Starting model training...\")\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True, verbose=1)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_list, y_train_dict,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_data=(X_val_list, y_val_dict),\n",
        "        callbacks=[early_stop],\n",
        "        verbose=1\n",
        "    )\n",
        "    print(\"Model training finished.\")\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLqUL7xbezi4"
      },
      "source": [
        "# --- Post-Processing ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qtcv4TpDez3v"
      },
      "outputs": [],
      "source": [
        "def adjust_outcomes(P, w_pred, d_pred, total_games, search_window):\n",
        "    \"\"\"\n",
        "    Adjusts continuous W/D/L predictions to integers satisfying 3W + D = P.\n",
        "\n",
        "    Args:\n",
        "        P (float): Predicted points (original scale).\n",
        "        w_pred (float): Predicted wins (continuous, scaled by total_games).\n",
        "        d_pred (float): Predicted draws (continuous, scaled by total_games).\n",
        "        total_games (int): Total games in the season.\n",
        "        search_window (int): Range (+/-) around initial win estimate to search.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (wins, draws, losses) as integers.\n",
        "    \"\"\"\n",
        "    target_points = int(round(P))\n",
        "    if target_points < 0: target_points = 0 # Points cannot be negative\n",
        "\n",
        "    # Estimate continuous W/D based on points and predicted ratio\n",
        "    # Avoid division by zero if w_pred + d_pred is zero or negative\n",
        "    if (w_pred + d_pred) <= 1e-6:\n",
        "         # If model predicts almost no wins or draws, base estimate on points/games\n",
        "         # Simple heuristic: assume mostly draws if points <= total_games, else max wins\n",
        "         if target_points <= total_games:\n",
        "             cont_w = 0\n",
        "             cont_d = float(target_points)\n",
        "         else:\n",
        "             cont_w = float(target_points) / 3.0\n",
        "             cont_d = 0.0\n",
        "    else:\n",
        "        # Use the model's predicted ratio of wins to (wins+draws)\n",
        "        r = w_pred / (w_pred + d_pred)\n",
        "        # Derive continuous W/D estimate satisfying 3*cont_w + cont_d = P\n",
        "        # P = 3*r*X + (1-r)*X => P = X*(3r + 1 - r) = X*(2r + 1) => X = P/(2r+1)\n",
        "        # where X is the estimated sum cont_w + cont_d\n",
        "        denominator = (2 * r + 1)\n",
        "        if abs(denominator) < 1e-6: # Avoid division by zero\n",
        "             X = float(total_games) # Fallback: assume all games contributed\n",
        "        else:\n",
        "             X = target_points / denominator\n",
        "        cont_w = r * X\n",
        "        cont_d = (1 - r) * X\n",
        "\n",
        "    best_error = float('inf')\n",
        "    best_tuple = None\n",
        "\n",
        "    # Search integer wins (w) in a window around the continuous estimate\n",
        "    search_start = max(0, int(round(cont_w)) - search_window)\n",
        "    search_end = int(round(cont_w)) + search_window + 1\n",
        "\n",
        "    for w in range(search_start, search_end):\n",
        "        # Calculate required draws (d) to match target points\n",
        "        d = target_points - 3 * w\n",
        "        if d < 0: # Cannot have negative draws\n",
        "            continue\n",
        "\n",
        "        # Calculate losses (l)\n",
        "        l = total_games - (w + d)\n",
        "        if l < 0: # Cannot have negative losses (w+d > total_games)\n",
        "            continue\n",
        "\n",
        "        # Check how close this integer solution (w, d) is to the continuous one\n",
        "        error = abs(w - cont_w) + abs(d - cont_d)\n",
        "\n",
        "        if error < best_error:\n",
        "            best_error = error\n",
        "            best_tuple = (w, d, l)\n",
        "\n",
        "    # Fallback if no valid (w, d, l) tuple was found in the search\n",
        "    if best_tuple is None:\n",
        "        # Simple fallback: prioritize points equation, then minimize impossible scenarios\n",
        "        # Try max wins first\n",
        "        w_fallback = target_points // 3\n",
        "        d_fallback = target_points % 3\n",
        "        l_fallback = total_games - (w_fallback + d_fallback)\n",
        "        if l_fallback < 0: # Too many points for the games? Adjust draws downwards\n",
        "             d_fallback += l_fallback # Reduce draws\n",
        "             l_fallback = 0\n",
        "             if d_fallback < 0: # Still impossible? Max wins, 0 draws, 0 losses (adjust points needed)\n",
        "                 w_fallback = total_games\n",
        "                 d_fallback = 0\n",
        "                 l_fallback = 0\n",
        "\n",
        "        best_tuple = (w_fallback, d_fallback, l_fallback)\n",
        "        # print(f\"Warning: adjust_outcomes fallback used for P={P}, w_pred={w_pred}, d_pred={d_pred}\")\n",
        "\n",
        "\n",
        "    # Ensure non-negativity just in case\n",
        "    final_w, final_d, final_l = best_tuple\n",
        "    final_w = max(0, final_w)\n",
        "    final_d = max(0, final_d)\n",
        "    final_l = max(0, final_l)\n",
        "\n",
        "    # Final sanity check: ensure sum equals total_games (due to rounding/fallbacks)\n",
        "    if final_w + final_d + final_l != total_games:\n",
        "        # If sum is off, adjust losses (least impactful on points)\n",
        "        final_l = total_games - (final_w + final_d)\n",
        "        final_l = max(0, final_l) # Ensure loss isn't negative after adjustment\n",
        "        # Re-check if w+d exceeds total_games after fixing L\n",
        "        if final_w + final_d > total_games:\n",
        "             # This should ideally not happen with prior checks, but as safeguard:\n",
        "             # Reduce draws first until w+d = total_games\n",
        "             reduction = (final_w + final_d) - total_games\n",
        "             final_d -= reduction\n",
        "             final_d = max(0, final_d)\n",
        "             # If draws went to 0 and still over, reduce wins\n",
        "             if final_w + final_d > total_games:\n",
        "                 reduction_w = (final_w + final_d) - total_games\n",
        "                 final_w -= reduction_w\n",
        "                 final_w = max(0, final_w)\n",
        "             final_l = 0 # Losses must be 0 now\n",
        "\n",
        "\n",
        "    return final_w, final_d, final_l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4GvdFC_e66A"
      },
      "source": [
        "# --- Prediction ---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPi1kSi5e7LL"
      },
      "outputs": [],
      "source": [
        "def predict_future(model, df_future_raw, encoders, imputers, scalers,\n",
        "                   numeric_features_cols, log_features_cols, gio_col, categorical_cols,\n",
        "                    # Removed unknown_token_id\n",
        "                   full_season_games, target_points_col,\n",
        "                   target_results_cols, adjust_search_window):\n",
        "    \"\"\"Prepares future data, makes predictions, and applies adjustments (handles unknowns by mapping to 0).\"\"\"\n",
        "    print(\"Starting prediction pipeline for future data...\")\n",
        "    df_pred_base = df_future_raw.copy()\n",
        "\n",
        "    # 1. Apply Log Transforms\n",
        "    # ... (keep existing log transform code) ...\n",
        "    print(\"Applying Log Transforms to prediction data...\")\n",
        "    for feature in log_features_cols:\n",
        "         if feature in df_pred_base.columns:\n",
        "             df_pred_base[feature] = df_pred_base[feature].clip(lower=0)\n",
        "             log_feature_name = f'{feature}_log'\n",
        "             df_pred_base[log_feature_name] = np.log1p(df_pred_base[feature])\n",
        "         else:\n",
        "            print(f\"Warning: Log feature '{feature}' not found in prediction data.\")\n",
        "\n",
        "    # 2. Impute Numeric Features first (using fitted imputer)\n",
        "    print(\"Applying imputation to prediction data...\")\n",
        "    numeric_imputed = imputers['numeric'].transform(df_pred_base[numeric_features_cols])\n",
        "    df_pred_base[numeric_features_cols] = numeric_imputed # Assign back before encoding\n",
        "\n",
        "    # 3. Apply Categorical Encoding (Handling Unknowns by mapping to 0)\n",
        "    print(\"Applying Label Encoding to prediction data (mapping unknowns to 0)...\")\n",
        "    categorical_label_cols = []\n",
        "    for col in categorical_cols:\n",
        "        le = encoders[col]\n",
        "        label_col = f'{col}_Label'\n",
        "        categorical_label_cols.append(label_col)\n",
        "        # Transform, mapping unknown values to 0\n",
        "        transformed_labels = []\n",
        "        for item in df_pred_base[col].astype(str):\n",
        "            if item in le.classes_:\n",
        "                # Add 1 to shift known labels away from 0\n",
        "                label = le.transform([item])[0] + 1\n",
        "                transformed_labels.append(label)\n",
        "            else: # Value not seen during fitting\n",
        "                print(f\"Info: Unknown value '{item}' found in column '{col}'. Mapping to 0.\")\n",
        "                transformed_labels.append(0) # Map unknowns to index 0\n",
        "        df_pred_base[label_col] = transformed_labels\n",
        "\n",
        "\n",
        "    # 4. Apply Scaling using fitted scalers (on imputed numeric data)\n",
        "    print(\"Applying scaling to prediction data...\")\n",
        "    X_pred_numeric_scaled = scalers['input'].transform(df_pred_base[numeric_features_cols]) # Use imputed data\n",
        "\n",
        "    # 5. Prepare all inputs for prediction\n",
        "    X_pred_team = df_pred_base['Team_Label'].values\n",
        "    X_pred_coach = df_pred_base['Coach_Label'].values\n",
        "    X_pred_gio = np.full((len(df_pred_base), 1), full_season_games, dtype=np.float32)\n",
        "\n",
        "    pred_inputs = [X_pred_numeric_scaled, X_pred_team, X_pred_coach, X_pred_gio]\n",
        "\n",
        "    # ... rest of prediction and adjustment code ...\n",
        "    # 6. Make Predictions\n",
        "    print(\"Making model predictions...\")\n",
        "    pred_points_scaled, pred_results_continuous = model.predict(pred_inputs)\n",
        "\n",
        "    # 7. Inverse Transform Points Predictions\n",
        "    pred_points_original = scalers['points'].inverse_transform(pred_points_scaled)\n",
        "    df_predictions = df_pred_base.copy()\n",
        "    df_predictions[target_points_col] = pred_points_original.flatten()\n",
        "\n",
        "    # 8. Apply Adjustment Function for Wins/Draws/Losses\n",
        "    print(\"Adjusting predicted outcomes...\")\n",
        "    adjusted_outcomes = df_predictions.apply(\n",
        "        lambda row: adjust_outcomes(\n",
        "            row[target_points_col],\n",
        "            pred_results_continuous[df_predictions.index.get_loc(row.name), 0], # Predicted Wins (cont)\n",
        "            pred_results_continuous[df_predictions.index.get_loc(row.name), 1], # Predicted Draws (cont)\n",
        "            total_games=full_season_games,\n",
        "            search_window=ADJUST_OUTCOMES_SEARCH_WINDOW # Use constant\n",
        "        ),\n",
        "        axis=1\n",
        "    )\n",
        "    # Assign adjusted integer outcomes\n",
        "    df_predictions[['Vit', 'Par', 'Sco']] = pd.DataFrame(adjusted_outcomes.tolist(), index=df_predictions.index)\n",
        "    df_predictions[f'{target_points_col}_Rounded'] = df_predictions[target_points_col].round().astype(int)\n",
        "\n",
        "\n",
        "    # 9. Final Sorting and Position Assignment\n",
        "    print(\"Assigning final positions...\")\n",
        "    df_predictions = df_predictions.sort_values(by=target_points_col, ascending=False).reset_index(drop=True)\n",
        "    df_predictions['Pos'] = range(1, len(df_predictions) + 1)\n",
        "\n",
        "\n",
        "    print(\"Prediction pipeline complete.\")\n",
        "    return df_predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7qp35h5fA8d"
      },
      "source": [
        "# --- Evaluation ---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RN0OxBJffBM6"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_val_list, y_val_dict_scaled, scaler_points, target_points_col, target_results_cols):\n",
        "    \"\"\"Evaluates the model on validation data.\"\"\"\n",
        "    print(\"\\n--- Model Evaluation on Validation Data ---\")\n",
        "    val_pred_points_scaled, val_pred_results_cont = model.predict(X_val_list)\n",
        "\n",
        "    # Inverse transform points predictions and actuals\n",
        "    val_pred_points_orig = scaler_points.inverse_transform(val_pred_points_scaled)\n",
        "    y_val_points_orig = scaler_points.inverse_transform(y_val_dict_scaled['points_output'])\n",
        "    y_val_results_orig = y_val_dict_scaled['results_output'] # These were not scaled\n",
        "\n",
        "    # Calculate metrics for points\n",
        "    mae_points = mean_absolute_error(y_val_points_orig, val_pred_points_orig)\n",
        "    rmse_points = np.sqrt(mean_squared_error(y_val_points_orig, val_pred_points_orig))\n",
        "    r2_points = r2_score(y_val_points_orig, val_pred_points_orig)\n",
        "    print(f\"Points Prediction ({target_points_col}):\")\n",
        "    print(f\"  MAE:  {mae_points:.2f}\")\n",
        "    print(f\"  RMSE: {rmse_points:.2f}\")\n",
        "    print(f\"  R²:   {r2_points:.2f}\")\n",
        "\n",
        "    # Calculate metrics for results (continuous predictions vs actual counts)\n",
        "    mae_results = mean_absolute_error(y_val_results_orig, val_pred_results_cont)\n",
        "    rmse_results = np.sqrt(mean_squared_error(y_val_results_orig, val_pred_results_cont))\n",
        "    # R2 might be less meaningful here if comparing continuous predictions to integer counts directly\n",
        "    print(f\"\\nResults Prediction ({', '.join(target_results_cols)}) - Continuous vs Actual Counts:\")\n",
        "    print(f\"  MAE (Avg per outcome): {mean_absolute_error(y_val_results_orig, val_pred_results_cont, multioutput='raw_values').mean():.2f}\")\n",
        "    print(f\"  RMSE (Avg per outcome): {np.sqrt(mean_squared_error(y_val_results_orig, val_pred_results_cont, multioutput='raw_values')).mean():.2f}\")\n",
        "    print(\"--------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3U_DVY6fH4_"
      },
      "source": [
        "# --- Explainability (SHAP) ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS-woeUafKMq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import shap\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from functools import partial # Keep this if using the partial approach\n",
        "\n",
        "# --- Explainability (SHAP using KernelExplainer) ---\n",
        "\n",
        "def explain_model_points(model, X_val_list, X_train_list, feature_names,\n",
        "                         output_dir, num_explain_samples=SHAP_EXPLAIN_SAMPLES, num_background_samples=SHAP_BACKGROUND_SAMPLES):\n",
        "    \"\"\"\n",
        "    Explains the points prediction using SHAP KernelExplainer.\n",
        "    Handles multi-input structure via a wrapper function.\n",
        "    Assumes model was trained WITHOUT mask_zero=True.\n",
        "    Expects X_val_list and X_train_list as lists of numpy arrays:\n",
        "       [X_numeric, X_team, X_coach, X_gio]\n",
        "    \"\"\"\n",
        "    print(\"\\n--- SHAP Explanation for Points Prediction (Using KernelExplainer) ---\")\n",
        "\n",
        "    # Unpack validation and training data lists - ensure numpy arrays\n",
        "    X_val_numeric, X_val_team, X_val_coach, X_val_gio = [np.asarray(arr) for arr in X_val_list]\n",
        "    X_train_numeric, X_train_team, X_train_coach, X_train_gio = [np.asarray(arr) for arr in X_train_list]\n",
        "\n",
        "    # --- Prepare Background Data Subset ---\n",
        "    if X_train_numeric.shape[0] < num_background_samples:\n",
        "        print(f\"Warning: Background samples requested ({num_background_samples}) > available training samples ({X_train_numeric.shape[0]}). Using all available.\")\n",
        "        num_background_samples = X_train_numeric.shape[0]\n",
        "    # Ensure background data is float32 numpy array for KernelExplainer\n",
        "    background_indices = np.random.choice(X_train_numeric.shape[0], num_background_samples, replace=False)\n",
        "    # KernelExplainer usually takes a summarized background (e.g., k-means) or a direct sample.\n",
        "    # Using a direct sample of the numeric part is common.\n",
        "    X_train_numeric_background = X_train_numeric[background_indices].astype(np.float32)\n",
        "    print(f\"Background data prepared with {num_background_samples} samples.\")\n",
        "\n",
        "    # --- Prepare Explanation Data Subset ---\n",
        "    if X_val_numeric.shape[0] < num_explain_samples:\n",
        "        print(f\"Warning: Explain samples requested ({num_explain_samples}) > available validation samples ({X_val_numeric.shape[0]}). Using all available.\")\n",
        "        num_explain_samples = X_val_numeric.shape[0]\n",
        "        explain_indices = np.arange(num_explain_samples)\n",
        "    else:\n",
        "        # Ensure reproducibility\n",
        "        np.random.seed(RANDOM_SEED)\n",
        "        explain_indices = np.random.choice(X_val_numeric.shape[0], num_explain_samples, replace=False)\n",
        "\n",
        "    # Select the subset to explain - ensure correct dtypes\n",
        "    X_explain_numeric = X_val_numeric[explain_indices].astype(np.float32)\n",
        "    X_explain_team = X_val_team[explain_indices].astype(np.int32)\n",
        "    X_explain_coach = X_val_coach[explain_indices].astype(np.int32)\n",
        "    X_explain_gio = X_val_gio[explain_indices].astype(np.float32)\n",
        "    print(f\"Explanation data prepared with {num_explain_samples} samples.\")\n",
        "\n",
        "\n",
        "    # --- Define the Prediction Function Wrapper for KernelExplainer ---\n",
        "    # This wrapper takes only the numeric data subset (as required by KernelExplainer)\n",
        "    # but uses the corresponding categorical and gio features internally,\n",
        "    # assuming SHAP passes data matching the order of X_explain_*.\n",
        "    def shap_predict_points_wrapper(X_numeric_subset):\n",
        "      # Ensure input is a float32 numpy array\n",
        "      X_numeric_subset = np.asarray(X_numeric_subset, dtype=np.float32)\n",
        "      if X_numeric_subset.ndim == 1:\n",
        "          X_numeric_subset = X_numeric_subset.reshape(1, -1)\n",
        "      num_instances = X_numeric_subset.shape[0]\n",
        "      predictions = np.zeros(num_instances)\n",
        "      for i in range(num_instances):\n",
        "          # Clip the index to avoid out-of-bounds: if i >= len(X_explain_team), use the last available sample.\n",
        "          idx = min(i, X_explain_team.shape[0] - 1)\n",
        "          current_team = X_explain_team[idx].reshape(1, 1)\n",
        "          current_coach = X_explain_coach[idx].reshape(1, 1)\n",
        "          current_gio = X_explain_gio[idx].reshape(1, 1)\n",
        "          current_numeric = X_numeric_subset[i].reshape(1, -1)\n",
        "          model_inputs = [\n",
        "              tf.constant(current_numeric, dtype=tf.float32),\n",
        "              tf.constant(current_team, dtype=tf.int32),\n",
        "              tf.constant(current_coach, dtype=tf.int32),\n",
        "              tf.constant(current_gio, dtype=tf.float32)\n",
        "          ]\n",
        "          try:\n",
        "              # Get prediction from your model (assuming it outputs [points, results])\n",
        "              pred_points_tensor, _ = model(model_inputs, training=False)\n",
        "              predictions[i] = pred_points_tensor.numpy().item()\n",
        "          except Exception as e:\n",
        "              print(f\"Error in SHAP wrapper for instance {i}: {e}\")\n",
        "              predictions[i] = np.nan\n",
        "      return predictions\n",
        "\n",
        "\n",
        "    # --- Initialize and Run KernelExplainer ---\n",
        "    shap_values = None\n",
        "    explainer = None\n",
        "    print(f\"Initializing KernelExplainer with {num_background_samples} background samples...\")\n",
        "    try:\n",
        "        # Note: KernelExplainer can be slow, especially for many samples or features.\n",
        "        explainer = shap.KernelExplainer(shap_predict_points_wrapper, X_train_numeric_background)\n",
        "\n",
        "        print(f\"Calculating SHAP values for {num_explain_samples} validation samples...\")\n",
        "        # Check for NaNs introduced by errors in the wrapper\n",
        "        first_pred = shap_predict_points_wrapper(X_explain_numeric[[0]])\n",
        "        if np.isnan(first_pred).any():\n",
        "             print(\"ERROR: SHAP wrapper function produced NaN for the first sample. Aborting SHAP calculation.\")\n",
        "             return None, None # Indicate failure\n",
        "\n",
        "        # Link=\"identity\" is default for regression-like outputs\n",
        "        shap_values = explainer.shap_values(X_explain_numeric, nsamples='auto') # Use auto nsamples\n",
        "        print(\"SHAP value calculation complete.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        print(f\"ERROR during SHAP KernelExplainer initialization or calculation: {e}\")\n",
        "        print(traceback.format_exc()) # Print detailed traceback\n",
        "        print(\"Skipping SHAP analysis due to error.\")\n",
        "        return None, None\n",
        "\n",
        "    # --- Generate and Save Plots ---\n",
        "    if shap_values is not None and isinstance(shap_values, np.ndarray):\n",
        "        print(\"Generating SHAP plots...\")\n",
        "        try:\n",
        "            # Summary Plot (Bar)\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            shap.summary_plot(shap_values, X_explain_numeric, feature_names=feature_names, plot_type=\"bar\", show=False)\n",
        "            plt.title(\"SHAP Feature Importance for Points Prediction (Numeric Features)\")\n",
        "            plt.tight_layout()\n",
        "            summary_path = os.path.join(output_dir, SHAP_SUMMARY_PLOT_FILE)\n",
        "            plt.savefig(summary_path)\n",
        "            plt.close()\n",
        "            print(f\"  Saved summary plot to: {summary_path}\")\n",
        "\n",
        "            # Dependence Plots for Top Numeric Features\n",
        "            mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
        "            num_top_features = min(3, len(feature_names))\n",
        "            if num_top_features > 0 and len(mean_abs_shap) > 0:\n",
        "                top_indices = np.argsort(mean_abs_shap)[-num_top_features:]\n",
        "                print(f\"  Generating dependence plots for top {num_top_features} numeric features...\")\n",
        "                for idx in top_indices:\n",
        "                    if idx < len(feature_names):\n",
        "                         plt.figure(figsize=(10, 6))\n",
        "                         shap.dependence_plot(idx, shap_values, X_explain_numeric, feature_names=feature_names, show=False)\n",
        "                         plt.tight_layout()\n",
        "                         safe_feature_name = \"\".join(c if c.isalnum() else \"_\" for c in feature_names[idx])\n",
        "                         dep_path = os.path.join(output_dir, f\"{SHAP_DEPENDENCE_PLOT_PREFIX}{safe_feature_name}.png\")\n",
        "                         plt.savefig(dep_path)\n",
        "                         plt.close()\n",
        "                         print(f\"    Saved dependence plot for '{feature_names[idx]}' to: {dep_path}\")\n",
        "                    else:\n",
        "                         print(f\"    Warning: Invalid index {idx} for dependence plot skipped.\")\n",
        "            elif len(feature_names) == 0:\n",
        "                 print(\"  Skipping dependence plots as no feature names were provided.\")\n",
        "            else:\n",
        "                 print(\"  Skipping dependence plots as unable to determine top features.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating SHAP plots: {e}\")\n",
        "            import traceback\n",
        "            print(traceback.format_exc())\n",
        "\n",
        "    elif shap_values is not None:\n",
        "         print(f\"Warning: SHAP values were computed but are not in the expected NumPy array format. Type: {type(shap_values)}. Skipping plotting.\")\n",
        "\n",
        "\n",
        "    print(\"--------------------------------------------\")\n",
        "    # KernelExplainer doesn't return separate values per input like DeepExplainer\n",
        "    # Return the single array of shap values (for numeric features) and the explainer\n",
        "    return shap_values, explainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgeT58L-oHu3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfatE4mFfj9F"
      },
      "source": [
        "# --- Main Execution ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ca8182a1d8d3404b9284694d6c7deda7",
            "917f148ea2ad478a8cdec5640d3837cf",
            "2adeb9fb8793416da72981b3492dfc95",
            "64d0a48b32514bc7835b70eb43f38fcd",
            "e4a2b632962b4329a754f5982cca21b5",
            "99d82c9010d94642b419b9fc35f8423b",
            "5ad2bebbc30844428e0f5dbf393fcc63",
            "e559138097ce4182a88a61642972a642",
            "0a76e11e8e8c43e7b74fecd025b27efb",
            "f13976efb4ed40108a34712b0194d298",
            "3648bb883d694300bb3f430842441b78"
          ]
        },
        "id": "sbU0THYBfmtE",
        "outputId": "098a181a-89ee-4fb9-f395-f93c326c3b7d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random seeds set to 42\n",
            "Data loaded successfully from /content/final_merged_data_with_transfers.csv. Shape: (302, 34)\n",
            "Applying Log Transforms...\n",
            "Applying median imputation to numeric features...\n",
            "Applying Label Encoding (starting labels from 1)...\n",
            "Encoded 'Team' into 'Team_Label'. Vocab size (incl. 0 for unknown): 21\n",
            "Encoded 'Coach' into 'Coach_Label'. Vocab size (incl. 0 for unknown): 103\n",
            "Training samples: 282, Validation samples: 17\n",
            "Scaling numeric input features...\n",
            "Scaling points target variable...\n",
            "Data scaling and preparation complete.\n",
            "Model compiled successfully (mask_zero=False).\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ team_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ coach_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ team_embedding            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │ team_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ coach_embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">824</span> │ coach_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ numeric_input             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ team_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ coach_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ numeric_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ flatten_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ flatten_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ results_probs             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ gio_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ points_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ results_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ results_probs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ gio_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ team_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ coach_input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ team_embedding            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)          │            \u001b[38;5;34m210\u001b[0m │ team_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ coach_embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │            \u001b[38;5;34m824\u001b[0m │ coach_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ numeric_input             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_8 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ team_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_9 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ coach_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ numeric_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ flatten_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ flatten_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │          \u001b[38;5;34m5,120\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m195\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ results_probs             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ gio_input (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ points_output (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m65\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ results_output (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ results_probs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ gio_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,670</span> (57.30 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,670\u001b[0m (57.30 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,670</span> (57.30 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,670\u001b[0m (57.30 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " *** Retraining model required due to mask_zero change *** \n",
            "\n",
            "Starting model training...\n",
            "Epoch 1/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 36.9493 - points_output_loss: 1.3320 - results_output_loss: 35.5896 - val_loss: 17.3554 - val_points_output_loss: 0.9359 - val_results_output_loss: 16.4195\n",
            "Epoch 2/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 25.7468 - points_output_loss: 1.0349 - results_output_loss: 24.7149 - val_loss: 17.7738 - val_points_output_loss: 0.7696 - val_results_output_loss: 17.0042\n",
            "Epoch 3/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 21.9421 - points_output_loss: 0.9095 - results_output_loss: 21.0237 - val_loss: 15.2881 - val_points_output_loss: 0.6940 - val_results_output_loss: 14.5941\n",
            "Epoch 4/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 17.8644 - points_output_loss: 0.7847 - results_output_loss: 17.0741 - val_loss: 12.5820 - val_points_output_loss: 0.6733 - val_results_output_loss: 11.9088\n",
            "Epoch 5/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 18.1781 - points_output_loss: 0.8048 - results_output_loss: 17.3584 - val_loss: 10.6993 - val_points_output_loss: 0.6451 - val_results_output_loss: 10.0542\n",
            "Epoch 6/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 16.6950 - points_output_loss: 0.7232 - results_output_loss: 15.9758 - val_loss: 9.5212 - val_points_output_loss: 0.6027 - val_results_output_loss: 8.9184\n",
            "Epoch 7/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 15.3514 - points_output_loss: 0.6960 - results_output_loss: 14.6549 - val_loss: 8.7426 - val_points_output_loss: 0.5356 - val_results_output_loss: 8.2069\n",
            "Epoch 8/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 17.3570 - points_output_loss: 0.6747 - results_output_loss: 16.6736 - val_loss: 8.5633 - val_points_output_loss: 0.5031 - val_results_output_loss: 8.0602\n",
            "Epoch 9/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 13.1488 - points_output_loss: 0.6306 - results_output_loss: 12.5119 - val_loss: 8.3431 - val_points_output_loss: 0.4794 - val_results_output_loss: 7.8637\n",
            "Epoch 10/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 14.2553 - points_output_loss: 0.6133 - results_output_loss: 13.6441 - val_loss: 7.9755 - val_points_output_loss: 0.4597 - val_results_output_loss: 7.5157\n",
            "Epoch 11/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 13.0428 - points_output_loss: 0.5066 - results_output_loss: 12.5524 - val_loss: 7.9578 - val_points_output_loss: 0.4310 - val_results_output_loss: 7.5268\n",
            "Epoch 12/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 12.4693 - points_output_loss: 0.5246 - results_output_loss: 11.9509 - val_loss: 7.9299 - val_points_output_loss: 0.4438 - val_results_output_loss: 7.4861\n",
            "Epoch 13/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 13.5753 - points_output_loss: 0.5234 - results_output_loss: 13.0608 - val_loss: 8.1929 - val_points_output_loss: 0.4492 - val_results_output_loss: 7.7437\n",
            "Epoch 14/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 12.3359 - points_output_loss: 0.5151 - results_output_loss: 11.8204 - val_loss: 7.7846 - val_points_output_loss: 0.4225 - val_results_output_loss: 7.3621\n",
            "Epoch 15/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11.7379 - points_output_loss: 0.5079 - results_output_loss: 11.2358 - val_loss: 7.5477 - val_points_output_loss: 0.4030 - val_results_output_loss: 7.1448\n",
            "Epoch 16/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 12.3120 - points_output_loss: 0.5671 - results_output_loss: 11.7526 - val_loss: 7.2219 - val_points_output_loss: 0.3688 - val_results_output_loss: 6.8531\n",
            "Epoch 17/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 11.7439 - points_output_loss: 0.4699 - results_output_loss: 11.2788 - val_loss: 7.0762 - val_points_output_loss: 0.3477 - val_results_output_loss: 6.7285\n",
            "Epoch 18/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11.0421 - points_output_loss: 0.5107 - results_output_loss: 10.5360 - val_loss: 6.9766 - val_points_output_loss: 0.3266 - val_results_output_loss: 6.6500\n",
            "Epoch 19/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11.2427 - points_output_loss: 0.4619 - results_output_loss: 10.7748 - val_loss: 6.9638 - val_points_output_loss: 0.3162 - val_results_output_loss: 6.6475\n",
            "Epoch 20/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11.0962 - points_output_loss: 0.4889 - results_output_loss: 10.5979 - val_loss: 6.8008 - val_points_output_loss: 0.2992 - val_results_output_loss: 6.5015\n",
            "Epoch 21/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10.3953 - points_output_loss: 0.4599 - results_output_loss: 9.9328 - val_loss: 6.7004 - val_points_output_loss: 0.2813 - val_results_output_loss: 6.4191\n",
            "Epoch 22/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11.2036 - points_output_loss: 0.4607 - results_output_loss: 10.7373 - val_loss: 6.8203 - val_points_output_loss: 0.2708 - val_results_output_loss: 6.5495\n",
            "Epoch 23/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10.5640 - points_output_loss: 0.4439 - results_output_loss: 10.1237 - val_loss: 6.7050 - val_points_output_loss: 0.2551 - val_results_output_loss: 6.4499\n",
            "Epoch 24/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.6187 - points_output_loss: 0.3819 - results_output_loss: 9.2417 - val_loss: 6.3506 - val_points_output_loss: 0.2323 - val_results_output_loss: 6.1183\n",
            "Epoch 25/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.6867 - points_output_loss: 0.4409 - results_output_loss: 9.2495 - val_loss: 6.1282 - val_points_output_loss: 0.2205 - val_results_output_loss: 5.9077\n",
            "Epoch 26/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.6762 - points_output_loss: 0.4352 - results_output_loss: 9.2364 - val_loss: 6.1637 - val_points_output_loss: 0.2203 - val_results_output_loss: 5.9434\n",
            "Epoch 27/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.3435 - points_output_loss: 0.4224 - results_output_loss: 8.9358 - val_loss: 5.8058 - val_points_output_loss: 0.2064 - val_results_output_loss: 5.5993\n",
            "Epoch 28/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10.1882 - points_output_loss: 0.4072 - results_output_loss: 9.7713 - val_loss: 5.6972 - val_points_output_loss: 0.1994 - val_results_output_loss: 5.4978\n",
            "Epoch 29/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.3253 - points_output_loss: 0.3620 - results_output_loss: 8.9741 - val_loss: 5.7088 - val_points_output_loss: 0.1902 - val_results_output_loss: 5.5187\n",
            "Epoch 30/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10.4072 - points_output_loss: 0.4210 - results_output_loss: 9.9936 - val_loss: 5.7697 - val_points_output_loss: 0.1814 - val_results_output_loss: 5.5883\n",
            "Epoch 31/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.2454 - points_output_loss: 0.3778 - results_output_loss: 8.8701 - val_loss: 5.6759 - val_points_output_loss: 0.1744 - val_results_output_loss: 5.5015\n",
            "Epoch 32/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.3830 - points_output_loss: 0.3486 - results_output_loss: 8.0375 - val_loss: 5.4336 - val_points_output_loss: 0.1644 - val_results_output_loss: 5.2692\n",
            "Epoch 33/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.8759 - points_output_loss: 0.3351 - results_output_loss: 8.5448 - val_loss: 5.6838 - val_points_output_loss: 0.1651 - val_results_output_loss: 5.5187\n",
            "Epoch 34/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.3836 - points_output_loss: 0.3306 - results_output_loss: 8.0588 - val_loss: 5.8698 - val_points_output_loss: 0.1624 - val_results_output_loss: 5.7074\n",
            "Epoch 35/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.6521 - points_output_loss: 0.2918 - results_output_loss: 7.3519 - val_loss: 5.8964 - val_points_output_loss: 0.1563 - val_results_output_loss: 5.7401\n",
            "Epoch 36/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.7073 - points_output_loss: 0.2866 - results_output_loss: 7.4252 - val_loss: 5.9112 - val_points_output_loss: 0.1541 - val_results_output_loss: 5.7571\n",
            "Epoch 37/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.6407 - points_output_loss: 0.3636 - results_output_loss: 8.2754 - val_loss: 5.6260 - val_points_output_loss: 0.1477 - val_results_output_loss: 5.4783\n",
            "Epoch 38/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.2361 - points_output_loss: 0.2912 - results_output_loss: 6.9436 - val_loss: 5.5451 - val_points_output_loss: 0.1506 - val_results_output_loss: 5.3945\n",
            "Epoch 39/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.6900 - points_output_loss: 0.3188 - results_output_loss: 7.3680 - val_loss: 5.4954 - val_points_output_loss: 0.1462 - val_results_output_loss: 5.3492\n",
            "Epoch 40/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.3200 - points_output_loss: 0.3016 - results_output_loss: 7.0225 - val_loss: 5.1456 - val_points_output_loss: 0.1344 - val_results_output_loss: 5.0112\n",
            "Epoch 41/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.0628 - points_output_loss: 0.3100 - results_output_loss: 7.7608 - val_loss: 4.9996 - val_points_output_loss: 0.1279 - val_results_output_loss: 4.8716\n",
            "Epoch 42/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.4843 - points_output_loss: 0.2388 - results_output_loss: 7.2412 - val_loss: 4.9532 - val_points_output_loss: 0.1251 - val_results_output_loss: 4.8280\n",
            "Epoch 43/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.3346 - points_output_loss: 0.2461 - results_output_loss: 7.0813 - val_loss: 4.9793 - val_points_output_loss: 0.1266 - val_results_output_loss: 4.8527\n",
            "Epoch 44/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.1189 - points_output_loss: 0.2796 - results_output_loss: 6.8409 - val_loss: 4.9558 - val_points_output_loss: 0.1285 - val_results_output_loss: 4.8273\n",
            "Epoch 45/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.9191 - points_output_loss: 0.2502 - results_output_loss: 6.6784 - val_loss: 4.7573 - val_points_output_loss: 0.1232 - val_results_output_loss: 4.6342\n",
            "Epoch 46/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.1644 - points_output_loss: 0.3187 - results_output_loss: 7.8400 - val_loss: 4.8851 - val_points_output_loss: 0.1354 - val_results_output_loss: 4.7497\n",
            "Epoch 47/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.2767 - points_output_loss: 0.2897 - results_output_loss: 7.9890 - val_loss: 4.7341 - val_points_output_loss: 0.1263 - val_results_output_loss: 4.6078\n",
            "Epoch 48/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.2968 - points_output_loss: 0.2403 - results_output_loss: 7.0525 - val_loss: 4.6773 - val_points_output_loss: 0.1142 - val_results_output_loss: 4.5631\n",
            "Epoch 49/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.7284 - points_output_loss: 0.2255 - results_output_loss: 6.5080 - val_loss: 4.6485 - val_points_output_loss: 0.1058 - val_results_output_loss: 4.5428\n",
            "Epoch 50/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.9858 - points_output_loss: 0.2797 - results_output_loss: 6.7155 - val_loss: 4.6321 - val_points_output_loss: 0.1030 - val_results_output_loss: 4.5291\n",
            "Epoch 51/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.5065 - points_output_loss: 0.2193 - results_output_loss: 7.2862 - val_loss: 5.1404 - val_points_output_loss: 0.1179 - val_results_output_loss: 5.0225\n",
            "Epoch 52/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.4077 - points_output_loss: 0.2523 - results_output_loss: 7.1580 - val_loss: 4.8709 - val_points_output_loss: 0.1224 - val_results_output_loss: 4.7484\n",
            "Epoch 53/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.9632 - points_output_loss: 0.2637 - results_output_loss: 6.6978 - val_loss: 4.4512 - val_points_output_loss: 0.1152 - val_results_output_loss: 4.3360\n",
            "Epoch 54/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.7280 - points_output_loss: 0.2476 - results_output_loss: 6.4737 - val_loss: 4.3109 - val_points_output_loss: 0.1119 - val_results_output_loss: 4.1990\n",
            "Epoch 55/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6.4715 - points_output_loss: 0.2417 - results_output_loss: 6.2289 - val_loss: 4.5409 - val_points_output_loss: 0.1201 - val_results_output_loss: 4.4208\n",
            "Epoch 56/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.4031 - points_output_loss: 0.2677 - results_output_loss: 7.1305 - val_loss: 4.4574 - val_points_output_loss: 0.1107 - val_results_output_loss: 4.3467\n",
            "Epoch 57/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.7543 - points_output_loss: 0.2540 - results_output_loss: 6.5062 - val_loss: 4.3913 - val_points_output_loss: 0.1034 - val_results_output_loss: 4.2879\n",
            "Epoch 58/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.2031 - points_output_loss: 0.2250 - results_output_loss: 5.9757 - val_loss: 4.2649 - val_points_output_loss: 0.1033 - val_results_output_loss: 4.1617\n",
            "Epoch 59/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.9192 - points_output_loss: 0.2132 - results_output_loss: 5.7018 - val_loss: 4.2634 - val_points_output_loss: 0.1062 - val_results_output_loss: 4.1572\n",
            "Epoch 60/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.6867 - points_output_loss: 0.2065 - results_output_loss: 6.4770 - val_loss: 4.1871 - val_points_output_loss: 0.1036 - val_results_output_loss: 4.0835\n",
            "Epoch 61/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.9744 - points_output_loss: 0.2234 - results_output_loss: 6.7461 - val_loss: 4.1971 - val_points_output_loss: 0.1012 - val_results_output_loss: 4.0959\n",
            "Epoch 62/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.0649 - points_output_loss: 0.2163 - results_output_loss: 5.8491 - val_loss: 4.1904 - val_points_output_loss: 0.1017 - val_results_output_loss: 4.0886\n",
            "Epoch 63/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.1545 - points_output_loss: 0.1915 - results_output_loss: 5.9643 - val_loss: 4.0904 - val_points_output_loss: 0.0973 - val_results_output_loss: 3.9930\n",
            "Epoch 64/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.9094 - points_output_loss: 0.2075 - results_output_loss: 5.6990 - val_loss: 4.1792 - val_points_output_loss: 0.0997 - val_results_output_loss: 4.0794\n",
            "Epoch 65/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.2995 - points_output_loss: 0.2450 - results_output_loss: 6.0470 - val_loss: 4.2261 - val_points_output_loss: 0.0984 - val_results_output_loss: 4.1278\n",
            "Epoch 66/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.5791 - points_output_loss: 0.1977 - results_output_loss: 5.3798 - val_loss: 3.9964 - val_points_output_loss: 0.0936 - val_results_output_loss: 3.9028\n",
            "Epoch 67/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.8405 - points_output_loss: 0.2076 - results_output_loss: 5.6298 - val_loss: 4.1805 - val_points_output_loss: 0.1035 - val_results_output_loss: 4.0771\n",
            "Epoch 68/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.7823 - points_output_loss: 0.2212 - results_output_loss: 5.5575 - val_loss: 3.9739 - val_points_output_loss: 0.0955 - val_results_output_loss: 3.8784\n",
            "Epoch 69/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.5269 - points_output_loss: 0.1956 - results_output_loss: 5.3335 - val_loss: 3.8042 - val_points_output_loss: 0.0910 - val_results_output_loss: 3.7132\n",
            "Epoch 70/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.8209 - points_output_loss: 0.1955 - results_output_loss: 5.6251 - val_loss: 3.9476 - val_points_output_loss: 0.0951 - val_results_output_loss: 3.8525\n",
            "Epoch 71/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.3063 - points_output_loss: 0.2484 - results_output_loss: 6.0570 - val_loss: 3.7236 - val_points_output_loss: 0.0922 - val_results_output_loss: 3.6314\n",
            "Epoch 72/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.8718 - points_output_loss: 0.2474 - results_output_loss: 5.6211 - val_loss: 3.5378 - val_points_output_loss: 0.0881 - val_results_output_loss: 3.4497\n",
            "Epoch 73/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.7771 - points_output_loss: 0.2059 - results_output_loss: 5.5619 - val_loss: 3.5817 - val_points_output_loss: 0.0902 - val_results_output_loss: 3.4915\n",
            "Epoch 74/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.9057 - points_output_loss: 0.2164 - results_output_loss: 4.6972 - val_loss: 3.4879 - val_points_output_loss: 0.0890 - val_results_output_loss: 3.3989\n",
            "Epoch 75/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.5075 - points_output_loss: 0.1827 - results_output_loss: 5.3221 - val_loss: 3.5245 - val_points_output_loss: 0.0862 - val_results_output_loss: 3.4383\n",
            "Epoch 76/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.4122 - points_output_loss: 0.2258 - results_output_loss: 5.1851 - val_loss: 3.6432 - val_points_output_loss: 0.0922 - val_results_output_loss: 3.5511\n",
            "Epoch 77/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.7783 - points_output_loss: 0.1912 - results_output_loss: 4.5870 - val_loss: 3.7406 - val_points_output_loss: 0.0969 - val_results_output_loss: 3.6437\n",
            "Epoch 78/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.6250 - points_output_loss: 0.2273 - results_output_loss: 5.3940 - val_loss: 3.5298 - val_points_output_loss: 0.0883 - val_results_output_loss: 3.4415\n",
            "Epoch 79/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.9548 - points_output_loss: 0.2008 - results_output_loss: 4.7516 - val_loss: 3.3608 - val_points_output_loss: 0.0861 - val_results_output_loss: 3.2747\n",
            "Epoch 80/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.7581 - points_output_loss: 0.1988 - results_output_loss: 5.5667 - val_loss: 3.3437 - val_points_output_loss: 0.0842 - val_results_output_loss: 3.2595\n",
            "Epoch 81/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.4285 - points_output_loss: 0.1858 - results_output_loss: 5.2452 - val_loss: 3.1617 - val_points_output_loss: 0.0760 - val_results_output_loss: 3.0857\n",
            "Epoch 82/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.3648 - points_output_loss: 0.1845 - results_output_loss: 5.1701 - val_loss: 2.8739 - val_points_output_loss: 0.0690 - val_results_output_loss: 2.8049\n",
            "Epoch 83/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.1560 - points_output_loss: 0.1738 - results_output_loss: 4.9804 - val_loss: 2.8426 - val_points_output_loss: 0.0647 - val_results_output_loss: 2.7779\n",
            "Epoch 84/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.4211 - points_output_loss: 0.1755 - results_output_loss: 5.2405 - val_loss: 2.9447 - val_points_output_loss: 0.0659 - val_results_output_loss: 2.8788\n",
            "Epoch 85/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.5189 - points_output_loss: 0.1968 - results_output_loss: 4.3213 - val_loss: 3.1342 - val_points_output_loss: 0.0739 - val_results_output_loss: 3.0603\n",
            "Epoch 86/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.4441 - points_output_loss: 0.1994 - results_output_loss: 5.2386 - val_loss: 3.1648 - val_points_output_loss: 0.0766 - val_results_output_loss: 3.0882\n",
            "Epoch 87/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.2636 - points_output_loss: 0.1750 - results_output_loss: 5.0816 - val_loss: 3.0272 - val_points_output_loss: 0.0761 - val_results_output_loss: 2.9511\n",
            "Epoch 88/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.5690 - points_output_loss: 0.1654 - results_output_loss: 4.3995 - val_loss: 3.0748 - val_points_output_loss: 0.0836 - val_results_output_loss: 2.9911\n",
            "Epoch 89/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.2154 - points_output_loss: 0.2308 - results_output_loss: 4.9821 - val_loss: 2.6813 - val_points_output_loss: 0.0723 - val_results_output_loss: 2.6089\n",
            "Epoch 90/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.0695 - points_output_loss: 0.1741 - results_output_loss: 4.8912 - val_loss: 2.7038 - val_points_output_loss: 0.0716 - val_results_output_loss: 2.6321\n",
            "Epoch 91/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.1764 - points_output_loss: 0.1757 - results_output_loss: 4.9976 - val_loss: 2.9046 - val_points_output_loss: 0.0819 - val_results_output_loss: 2.8228\n",
            "Epoch 92/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.5950 - points_output_loss: 0.1596 - results_output_loss: 4.4375 - val_loss: 2.8241 - val_points_output_loss: 0.0826 - val_results_output_loss: 2.7415\n",
            "Epoch 93/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.5533 - points_output_loss: 0.1994 - results_output_loss: 4.3513 - val_loss: 2.4762 - val_points_output_loss: 0.0676 - val_results_output_loss: 2.4087\n",
            "Epoch 94/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.0206 - points_output_loss: 0.1694 - results_output_loss: 4.8481 - val_loss: 2.5646 - val_points_output_loss: 0.0717 - val_results_output_loss: 2.4929\n",
            "Epoch 95/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.9676 - points_output_loss: 0.1574 - results_output_loss: 4.8015 - val_loss: 2.7134 - val_points_output_loss: 0.0794 - val_results_output_loss: 2.6341\n",
            "Epoch 96/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.1302 - points_output_loss: 0.2136 - results_output_loss: 4.9101 - val_loss: 2.6847 - val_points_output_loss: 0.0756 - val_results_output_loss: 2.6091\n",
            "Epoch 97/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.3525 - points_output_loss: 0.1691 - results_output_loss: 4.1815 - val_loss: 2.5763 - val_points_output_loss: 0.0708 - val_results_output_loss: 2.5055\n",
            "Epoch 98/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.1935 - points_output_loss: 0.1673 - results_output_loss: 5.0224 - val_loss: 2.2687 - val_points_output_loss: 0.0586 - val_results_output_loss: 2.2101\n",
            "Epoch 99/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.5699 - points_output_loss: 0.1790 - results_output_loss: 4.3849 - val_loss: 2.1253 - val_points_output_loss: 0.0554 - val_results_output_loss: 2.0699\n",
            "Epoch 100/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.9895 - points_output_loss: 0.1983 - results_output_loss: 4.7873 - val_loss: 1.9865 - val_points_output_loss: 0.0512 - val_results_output_loss: 1.9353\n",
            "Epoch 101/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.4107 - points_output_loss: 0.1665 - results_output_loss: 4.2421 - val_loss: 2.4011 - val_points_output_loss: 0.0632 - val_results_output_loss: 2.3379\n",
            "Epoch 102/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.7945 - points_output_loss: 0.1696 - results_output_loss: 4.6243 - val_loss: 2.3389 - val_points_output_loss: 0.0616 - val_results_output_loss: 2.2773\n",
            "Epoch 103/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.8602 - points_output_loss: 0.1388 - results_output_loss: 3.7181 - val_loss: 2.0384 - val_points_output_loss: 0.0521 - val_results_output_loss: 1.9862\n",
            "Epoch 104/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.2271 - points_output_loss: 0.1429 - results_output_loss: 4.0800 - val_loss: 2.0232 - val_points_output_loss: 0.0492 - val_results_output_loss: 1.9740\n",
            "Epoch 105/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.8877 - points_output_loss: 0.1741 - results_output_loss: 4.7088 - val_loss: 1.8411 - val_points_output_loss: 0.0468 - val_results_output_loss: 1.7943\n",
            "Epoch 106/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.4628 - points_output_loss: 0.1639 - results_output_loss: 4.2951 - val_loss: 1.7737 - val_points_output_loss: 0.0459 - val_results_output_loss: 1.7278\n",
            "Epoch 107/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.2714 - points_output_loss: 0.1573 - results_output_loss: 4.1151 - val_loss: 1.6423 - val_points_output_loss: 0.0395 - val_results_output_loss: 1.6028\n",
            "Epoch 108/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.3814 - points_output_loss: 0.1429 - results_output_loss: 4.2371 - val_loss: 1.6081 - val_points_output_loss: 0.0357 - val_results_output_loss: 1.5724\n",
            "Epoch 109/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.3460 - points_output_loss: 0.1590 - results_output_loss: 4.1905 - val_loss: 1.6482 - val_points_output_loss: 0.0376 - val_results_output_loss: 1.6106\n",
            "Epoch 110/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.2625 - points_output_loss: 0.1498 - results_output_loss: 4.1123 - val_loss: 1.6391 - val_points_output_loss: 0.0391 - val_results_output_loss: 1.6001\n",
            "Epoch 111/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.4014 - points_output_loss: 0.1551 - results_output_loss: 4.2447 - val_loss: 1.6891 - val_points_output_loss: 0.0400 - val_results_output_loss: 1.6491\n",
            "Epoch 112/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.1170 - points_output_loss: 0.1714 - results_output_loss: 3.9415 - val_loss: 1.8274 - val_points_output_loss: 0.0465 - val_results_output_loss: 1.7808\n",
            "Epoch 113/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.7721 - points_output_loss: 0.1889 - results_output_loss: 4.5753 - val_loss: 1.7042 - val_points_output_loss: 0.0444 - val_results_output_loss: 1.6598\n",
            "Epoch 114/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.9307 - points_output_loss: 0.1321 - results_output_loss: 3.7991 - val_loss: 1.5154 - val_points_output_loss: 0.0362 - val_results_output_loss: 1.4792\n",
            "Epoch 115/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.0610 - points_output_loss: 0.1416 - results_output_loss: 3.9135 - val_loss: 1.5171 - val_points_output_loss: 0.0348 - val_results_output_loss: 1.4823\n",
            "Epoch 116/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.8116 - points_output_loss: 0.1486 - results_output_loss: 3.6641 - val_loss: 1.6678 - val_points_output_loss: 0.0423 - val_results_output_loss: 1.6255\n",
            "Epoch 117/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.0746 - points_output_loss: 0.1639 - results_output_loss: 3.9055 - val_loss: 1.6471 - val_points_output_loss: 0.0425 - val_results_output_loss: 1.6046\n",
            "Epoch 118/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.3097 - points_output_loss: 0.1663 - results_output_loss: 4.1448 - val_loss: 1.5692 - val_points_output_loss: 0.0405 - val_results_output_loss: 1.5287\n",
            "Epoch 119/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.8179 - points_output_loss: 0.1599 - results_output_loss: 3.6588 - val_loss: 1.6946 - val_points_output_loss: 0.0486 - val_results_output_loss: 1.6460\n",
            "Epoch 120/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.2036 - points_output_loss: 0.1593 - results_output_loss: 4.0401 - val_loss: 2.0279 - val_points_output_loss: 0.0608 - val_results_output_loss: 1.9671\n",
            "Epoch 121/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.3053 - points_output_loss: 0.1427 - results_output_loss: 4.1631 - val_loss: 1.9034 - val_points_output_loss: 0.0541 - val_results_output_loss: 1.8493\n",
            "Epoch 122/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.1711 - points_output_loss: 0.1321 - results_output_loss: 4.0391 - val_loss: 1.8771 - val_points_output_loss: 0.0550 - val_results_output_loss: 1.8222\n",
            "Epoch 123/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.9632 - points_output_loss: 0.1405 - results_output_loss: 3.8206 - val_loss: 1.7774 - val_points_output_loss: 0.0519 - val_results_output_loss: 1.7254\n",
            "Epoch 124/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.3775 - points_output_loss: 0.1268 - results_output_loss: 3.2505 - val_loss: 1.8677 - val_points_output_loss: 0.0581 - val_results_output_loss: 1.8096\n",
            "Epoch 125/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.7884 - points_output_loss: 0.1482 - results_output_loss: 3.6396 - val_loss: 1.6565 - val_points_output_loss: 0.0500 - val_results_output_loss: 1.6065\n",
            "Epoch 126/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.9576 - points_output_loss: 0.1428 - results_output_loss: 3.8105 - val_loss: 1.4656 - val_points_output_loss: 0.0409 - val_results_output_loss: 1.4247\n",
            "Epoch 127/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.7081 - points_output_loss: 0.1262 - results_output_loss: 3.5808 - val_loss: 1.5203 - val_points_output_loss: 0.0411 - val_results_output_loss: 1.4792\n",
            "Epoch 128/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.0584 - points_output_loss: 0.1442 - results_output_loss: 3.9099 - val_loss: 1.4755 - val_points_output_loss: 0.0377 - val_results_output_loss: 1.4378\n",
            "Epoch 129/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.0832 - points_output_loss: 0.1419 - results_output_loss: 3.9387 - val_loss: 1.3965 - val_points_output_loss: 0.0355 - val_results_output_loss: 1.3611\n",
            "Epoch 130/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.5695 - points_output_loss: 0.1429 - results_output_loss: 3.4292 - val_loss: 1.4249 - val_points_output_loss: 0.0384 - val_results_output_loss: 1.3865\n",
            "Epoch 131/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.3201 - points_output_loss: 0.1422 - results_output_loss: 4.1766 - val_loss: 1.3760 - val_points_output_loss: 0.0370 - val_results_output_loss: 1.3390\n",
            "Epoch 132/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.8864 - points_output_loss: 0.1618 - results_output_loss: 3.7167 - val_loss: 1.2874 - val_points_output_loss: 0.0323 - val_results_output_loss: 1.2551\n",
            "Epoch 133/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.0569 - points_output_loss: 0.1483 - results_output_loss: 3.9036 - val_loss: 1.3292 - val_points_output_loss: 0.0334 - val_results_output_loss: 1.2958\n",
            "Epoch 134/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.0067 - points_output_loss: 0.1526 - results_output_loss: 3.8517 - val_loss: 1.1500 - val_points_output_loss: 0.0232 - val_results_output_loss: 1.1268\n",
            "Epoch 135/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.7035 - points_output_loss: 0.1427 - results_output_loss: 3.5595 - val_loss: 1.1201 - val_points_output_loss: 0.0235 - val_results_output_loss: 1.0966\n",
            "Epoch 136/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.5211 - points_output_loss: 0.1372 - results_output_loss: 3.3806 - val_loss: 1.3988 - val_points_output_loss: 0.0335 - val_results_output_loss: 1.3653\n",
            "Epoch 137/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.1705 - points_output_loss: 0.1954 - results_output_loss: 3.9727 - val_loss: 1.2041 - val_points_output_loss: 0.0261 - val_results_output_loss: 1.1780\n",
            "Epoch 138/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.6574 - points_output_loss: 0.1293 - results_output_loss: 3.5281 - val_loss: 1.3735 - val_points_output_loss: 0.0333 - val_results_output_loss: 1.3401\n",
            "Epoch 139/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.5352 - points_output_loss: 0.1181 - results_output_loss: 3.4201 - val_loss: 1.2460 - val_points_output_loss: 0.0273 - val_results_output_loss: 1.2187\n",
            "Epoch 140/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.3676 - points_output_loss: 0.1158 - results_output_loss: 3.2471 - val_loss: 0.9925 - val_points_output_loss: 0.0190 - val_results_output_loss: 0.9735\n",
            "Epoch 141/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.8836 - points_output_loss: 0.1593 - results_output_loss: 3.7201 - val_loss: 1.0959 - val_points_output_loss: 0.0268 - val_results_output_loss: 1.0691\n",
            "Epoch 142/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.3697 - points_output_loss: 0.1277 - results_output_loss: 3.2407 - val_loss: 1.3650 - val_points_output_loss: 0.0395 - val_results_output_loss: 1.3255\n",
            "Epoch 143/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.3174 - points_output_loss: 0.1235 - results_output_loss: 3.1928 - val_loss: 1.1616 - val_points_output_loss: 0.0328 - val_results_output_loss: 1.1288\n",
            "Epoch 144/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.5700 - points_output_loss: 0.1408 - results_output_loss: 3.4244 - val_loss: 1.1141 - val_points_output_loss: 0.0291 - val_results_output_loss: 1.0851\n",
            "Epoch 145/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.9332 - points_output_loss: 0.1286 - results_output_loss: 3.8021 - val_loss: 1.2500 - val_points_output_loss: 0.0341 - val_results_output_loss: 1.2159\n",
            "Epoch 146/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.7896 - points_output_loss: 0.1267 - results_output_loss: 3.6551 - val_loss: 1.1203 - val_points_output_loss: 0.0279 - val_results_output_loss: 1.0924\n",
            "Epoch 147/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.5816 - points_output_loss: 0.1310 - results_output_loss: 3.4486 - val_loss: 1.0349 - val_points_output_loss: 0.0251 - val_results_output_loss: 1.0098\n",
            "Epoch 148/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.9673 - points_output_loss: 0.1334 - results_output_loss: 3.8285 - val_loss: 1.2958 - val_points_output_loss: 0.0373 - val_results_output_loss: 1.2585\n",
            "Epoch 149/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.7930 - points_output_loss: 0.1393 - results_output_loss: 3.6528 - val_loss: 1.2480 - val_points_output_loss: 0.0384 - val_results_output_loss: 1.2096\n",
            "Epoch 150/150\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.4626 - points_output_loss: 0.1311 - results_output_loss: 3.3315 - val_loss: 1.0600 - val_points_output_loss: 0.0315 - val_results_output_loss: 1.0284\n",
            "Restoring model weights from the end of the best epoch: 140.\n",
            "Model training finished.\n",
            "\n",
            "--- Model Evaluation on Validation Data ---\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
            "Points Prediction (Pti):\n",
            "  MAE:  1.74\n",
            "  RMSE: 2.32\n",
            "  R²:   0.98\n",
            "\n",
            "Results Prediction (Vit, Par, Sco) - Continuous vs Actual Counts:\n",
            "  MAE (Avg per outcome): 0.76\n",
            "  RMSE (Avg per outcome): 0.98\n",
            "--------------------------------------------\n",
            "Starting prediction pipeline for future data...\n",
            "Applying Log Transforms to prediction data...\n",
            "Applying imputation to prediction data...\n",
            "Applying Label Encoding to prediction data (mapping unknowns to 0)...\n",
            "Applying scaling to prediction data...\n",
            "Making model predictions...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step\n",
            "Adjusting predicted outcomes...\n",
            "Assigning final positions...\n",
            "Prediction pipeline complete.\n",
            "\n",
            "--- Final Predictions for Year 2025 ---\n",
            "    Pos               Team  Pti_Rounded  Vit  Par  Sco\n",
            "0     1        Inter Milan           85   25   10    3\n",
            "1     2        Atalanta BC           80   24    8    6\n",
            "2     3         SSC Napoli           74   21   11    6\n",
            "3     4           AC Milan           73   22    7    9\n",
            "4     5        Juventus FC           72   20   12    6\n",
            "5     6            AS Roma           64   18   10   10\n",
            "6     7     ACF Fiorentina           62   17   11   10\n",
            "7     8           SS Lazio           60   17    9   12\n",
            "8     9    Bologna FC 1909           59   17    8   13\n",
            "9    10          Genoa CFC           54   15    9   14\n",
            "10   11           AC Monza           51   13   12   13\n",
            "11   12  Parma Calcio 1913           49   13   10   15\n",
            "12   13          Torino FC           49   13   10   15\n",
            "13   14          Como 1907           48   12   12   14\n",
            "14   15     Udinese Calcio           45   12    9   17\n",
            "15   16           US Lecce           41   10   11   17\n",
            "16   17         Venezia FC           41   10   11   17\n",
            "17   18          Empoli FC           40   10   10   18\n",
            "18   19    Cagliari Calcio           38    9   11   18\n",
            "19   20      Hellas Verona           36    8   12   18\n",
            "\n",
            "Final predictions saved to 'final_2025_predictions_refactored.csv'\n",
            "\n",
            "--- SHAP Explanation for Points Prediction (Using KernelExplainer) ---\n",
            "Background data prepared with 20 samples.\n",
            "Explanation data prepared with 10 samples.\n",
            "Initializing KernelExplainer with 20 background samples...\n",
            "Calculating SHAP values for 10 validation samples...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca8182a1d8d3404b9284694d6c7deda7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SHAP value calculation complete.\n",
            "Generating SHAP plots...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-87-3614f2ffe5cf>:120: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  shap.summary_plot(shap_values, X_explain_numeric, feature_names=feature_names, plot_type=\"bar\", show=False)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Saved summary plot to: output_plots/shap_summary_plot.png\n",
            "  Generating dependence plots for top 3 numeric features...\n",
            "    Saved dependence plot for 'Average Market Value' to: output_plots/shap_dependence_Average_Market_Value.png\n",
            "    Saved dependence plot for 'Market Value OUT Players' to: output_plots/shap_dependence_Market_Value_OUT_Players.png\n",
            "    Saved dependence plot for 'Average Market Value_log' to: output_plots/shap_dependence_Average_Market_Value_log.png\n",
            "--------------------------------------------\n",
            "\n",
            "Analysis Complete.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    set_seeds(RANDOM_SEED)\n",
        "    output_plot_dir = create_output_directory()\n",
        "\n",
        "    # 1. Load Data\n",
        "    df_raw = load_data(DATA_FILEPATH)\n",
        "\n",
        "    if df_raw is not None:\n",
        "        # 2. Preprocess Data (Log transforms, Imputation, Categorical Encoding starting from 1)\n",
        "        # Note: Imputation now happens inside preprocess_data before encoding is finalized\n",
        "        df_processed, encoders, final_numeric_features, imputers, categorical_label_cols = preprocess_data(\n",
        "            df_raw, TARGET_POINTS_COL, TARGET_RESULTS_COLS, BASE_INPUT_FEATURES,\n",
        "            LOG_TRANSFORM_COLS, GIO_COL, CATEGORICAL_COLS, IMPUTATION_STRATEGY\n",
        "        )\n",
        "\n",
        "        # 3. Split and Scale Data for Training/Validation\n",
        "        train_indices = df_processed[df_processed['Year'] <= LAST_COMPLETED_YEAR].index\n",
        "        val_indices = df_processed[df_processed['Year'] == LAST_COMPLETED_YEAR].index\n",
        "        print(f\"Training samples: {len(train_indices)}, Validation samples: {len(val_indices)}\")\n",
        "\n",
        "        # Pass imputers dict returned from preprocess_data\n",
        "        X_train_list, y_train_dict, X_val_list, y_val_dict_scaled, scalers = \\\n",
        "          prepare_scaled_data_for_training(\n",
        "              df_processed, train_indices, val_indices, final_numeric_features,\n",
        "              GIO_COL, TARGET_POINTS_COL, TARGET_RESULTS_COLS,\n",
        "              categorical_label_cols # Remove imputers from the call arguments\n",
        "          )\n",
        "\n",
        "        # ***Need to adjust prepare_scaled_data_for_training***\n",
        "        # It now receives imputed data via df_processed and shouldn't redo imputation.\n",
        "        # Let's assume prepare_scaled_data_for_training is modified appropriately\n",
        "        # to just do splitting and scaling based on df_processed.\n",
        "\n",
        "        # 4. Build Model (without mask_zero)\n",
        "        num_teams = len(encoders['Team'].classes_)\n",
        "        num_coaches = len(encoders['Coach'].classes_)\n",
        "        model = build_multitask_model(\n",
        "            num_numeric_features=len(final_numeric_features),\n",
        "            num_teams=num_teams,\n",
        "            num_coaches=num_coaches,\n",
        "            team_embedding_dim=TEAM_EMBEDDING_DIM,\n",
        "            coach_embedding_dim=COACH_EMBEDDING_DIM,\n",
        "            dropout_rate=DROPOUT_RATE,\n",
        "            learning_rate=LEARNING_RATE,\n",
        "            loss_weights=LOSS_WEIGHTS\n",
        "        )\n",
        "\n",
        "        # 5. Train Model (Requires retraining after changing model structure)\n",
        "        print(\"\\n *** Retraining model required due to mask_zero change *** \\n\")\n",
        "        model, history = train_model(\n",
        "            model, X_train_list, y_train_dict, X_val_list, y_val_dict_scaled,\n",
        "            epochs=EPOCHS, batch_size=BATCH_SIZE, patience=EARLY_STOPPING_PATIENCE\n",
        "        )\n",
        "\n",
        "        # 6. Evaluate Model\n",
        "        evaluate_model(model, X_val_list, y_val_dict_scaled, scalers['points'],\n",
        "                       TARGET_POINTS_COL, TARGET_RESULTS_COLS)\n",
        "\n",
        "        # 7. Predict Future Season\n",
        "        future_data_raw = df_raw[df_raw['Year'] == LAST_COMPLETED_YEAR + 1].copy()\n",
        "        if not future_data_raw.empty:\n",
        "             df_future_base = future_data_raw.drop_duplicates(subset=['Team'], keep='last').reset_index(drop=True)\n",
        "             df_future_base['Year'] = LAST_COMPLETED_YEAR + PREDICTION_YEAR_OFFSET\n",
        "\n",
        "             final_predictions = predict_future( # Call updated predict_future\n",
        "                 model, df_future_base, encoders, imputers, scalers,\n",
        "                 final_numeric_features, LOG_TRANSFORM_COLS, GIO_COL, CATEGORICAL_COLS,\n",
        "                 # unknown_token_id no longer needed here\n",
        "                 FULL_SEASON_GAMES, TARGET_POINTS_COL,\n",
        "                 TARGET_RESULTS_COLS, ADJUST_OUTCOMES_SEARCH_WINDOW\n",
        "             )\n",
        "             # ... display and save predictions ...\n",
        "             print(\"\\n--- Final Predictions for Year\", LAST_COMPLETED_YEAR + PREDICTION_YEAR_OFFSET, \"---\")\n",
        "             display_cols = ['Pos', 'Team', f'{TARGET_POINTS_COL}_Rounded'] + TARGET_RESULTS_COLS\n",
        "             # Ensure columns exist before printing\n",
        "             display_cols = [col for col in display_cols if col in final_predictions.columns]\n",
        "             print(final_predictions[display_cols])\n",
        "             try:\n",
        "                 final_predictions.to_csv(PREDICTIONS_OUTPUT_FILE, index=False)\n",
        "                 print(f\"\\nFinal predictions saved to '{PREDICTIONS_OUTPUT_FILE}'\")\n",
        "             except Exception as e:\n",
        "                 print(f\"\\nError saving predictions to CSV: {e}\")\n",
        "\n",
        "        else:\n",
        "             print(\"\\nSkipping future prediction as no data found for Year\", LAST_COMPLETED_YEAR + 1)\n",
        "\n",
        "\n",
        "        # 8. Explain Model (SHAP)\n",
        "        shap_values_list, explainer = explain_model_points( # Call the same explain function\n",
        "            model, X_val_list, X_train_list,\n",
        "            final_numeric_features, output_plot_dir,\n",
        "            num_explain_samples=SHAP_EXPLAIN_SAMPLES,\n",
        "            num_background_samples=SHAP_BACKGROUND_SAMPLES\n",
        "        )\n",
        "\n",
        "        print(\"\\nAnalysis Complete.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNT1Ft/VqR1v61xORY8VeB8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}